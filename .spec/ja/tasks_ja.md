# 実装計画

- [ ] 1. プロジェクト構造とコアデータモデルのセットアップ
  - `uv init`を使用してPython 3.13プロジェクトを初期化
  - プロジェクトメタデータと依存関係を含むpyproject.tomlを作成
  - CrawlResult、UrlInfo、FailedUrl、CrawlerConfigのデータクラスをbase_urlとbase_pathフィールド付きで定義
  - ウェブクローラーパッケージのディレクトリ構造と__init__.pyファイルを作成
  - _要件: 1.1, 4.3_

- [ ] 2. URL管理と検証コンポーネントの実装
  - [ ] 2.1 ドメインとパススコープチェックロジック付きDomainValidatorクラスの作成
    - URLが同じドメインに属するかチェックするis_same_domainメソッドを実装
    - URLからドメインを解析するextract_domainメソッドを追加
    - URLパス階層を検証するis_within_path_scopeメソッドを実装
    - パススコープ検証のためのパス正規化と比較ロジックを追加
    - ドメイン検証とパススコープロジックのユニットテストを作成
    - _要件: 2.1, 2.2, 2.3, 2.4, 2.5, 2.6_

  - [ ] 2.2 キューと訪問済みURL追跡のためのURLManagerクラスの実装
    - 深度追跡付きのURLキュー管理を作成
    - 重複を防ぐための訪問済みURLセットを実装
    - URL追加、取得、チェックのメソッドを追加
    - URL管理操作のユニットテストを作成
    - _要件: 3.1, 3.2, 3.3_

- [ ] 3. エラーハンドリングと再試行ロジック付きHTTPクライアントの作成
  - [ ] 3.1 基本リクエスト機能付きHTTPClientクラスの実装
    - タイムアウトとユーザーエージェントヘッダー付きfetch_pageメソッドを作成
    - レスポンス検証とステータスコード処理を追加
    - 基本HTTP機能のユニットテストを作成
    - _要件: 5.1, 5.3_

  - [ ] 3.2 HTTPClientに再試行ロジックとレート制限を追加
    - 指数バックオフ再試行メカニズムを実装
    - リクエスト間の設定可能な遅延を追加
    - ネットワークタイムアウトと接続エラーを適切に処理
    - 再試行とレート制限動作のユニットテストを作成
    - _要件: 5.3, 5.4_

- [ ] 4. HTML解析とリンク抽出の実装
  - BeautifulSoupベースのHTML解析付きLinkExtractorクラスを作成
  - すべてのhref属性を見つけるextract_linksメソッドを実装
  - URL正規化と相対URL解決を追加
  - 非HTTPスキーム（mailto、javascript等）をフィルタリング
  - リンク抽出とURL正規化のユニットテストを作成
  - _要件: 1.2, 5.2_

- [ ] 5. 設定管理システムの作成
  - コマンドライン引数解析のためのConfigManagerクラスを実装
  - デフォルト設定値と検証を定義
  - max_depth、delay、timeout、output_formatオプションのサポートを追加
  - 設定解析と検証のユニットテストを作成
  - _要件: 6.1, 6.2, 6.3, 6.4_

- [ ] 6. 出力フォーマットと表示の実装
  - [ ] 6.1 テキスト出力サポート付きOutputFormatterクラスの作成
    - URLの階層ツリー構造表示を実装
    - クロールプロセス中の進捗報告を追加
    - 要約統計表示を作成
    - テキストフォーマットのユニットテストを作成
    - _要件: 4.1, 4.2, 4.3_

  - [ ] 6.2 JSONとCSV出力形式サポートの追加
    - CrawlResultデータのJSONシリアライゼーションを実装
    - 適切な列ヘッダー付きCSVエクスポート機能を追加
    - 異なる出力形式のユニットテストを作成
    - _要件: 6.4_

- [ ] 7. メインクローラーコントローラーと統制の作成
  - [ ] 7.1 WebLinkCrawlerメインクラスの実装
    - クロールプロセスを統制するcrawlメソッドを作成
    - キュー処理付きメインクロールループを実装
    - 深度制限チェックとURL処理調整を追加
    - クローラー統制ロジックのユニットテストを作成
    - _要件: 1.1, 1.3, 1.4, 3.3_

  - [ ] 7.2 エラーハンドリングと適切なシャットダウンの追加
    - すべての失敗シナリオに対する包括的エラーハンドリングを実装
    - 適切なシャットダウン機能と結果コンパイルを追加
    - 不正なHTMLや無効なURLなどのエッジケースを処理
    - エラーハンドリングシナリオのユニットテストを作成
    - _要件: 4.4, 5.1, 5.2_

- [ ] 8. コマンドラインインターフェースとエントリーポイントの作成
  - 引数解析付きメインCLIスクリプトを実装
  - ヘルプテキストと使用例を追加
  - uv実行のためのpyproject.tomlでエントリーポイントを設定
  - `uv run web-link-crawler`で実行できるスクリプトを作成
  - 完全なCLIワークフローの統合テストを作成
  - _要件: 6.1, 6.5_

- [ ] 9. 包括的テストと検証の追加
  - [ ] 9.1 モックHTTPレスポンス付き統合テストの作成
    - クロール動作テスト用のモックウェブサーバーをセットアップ
    - 様々なHTML構造での完全なクロールワークフローをテスト
    - 深度制限、ドメイン境界強制、パススコープ制限を検証
    - 様々なURL構造でのパス階層検証をテスト
    - _要件: 1.4, 2.4, 2.5, 2.6, 3.4_

  - [ ] 9.2 パフォーマンスとエッジケーステストの追加
    - 大きなURLセットでのメモリ使用量をテスト
    - 循環参照と無限ループでの動作を検証
    - 失敗後のエラー回復と継続をテスト
    - _要件: 3.4, 5.1, 5.2, 5.3_

- [ ] 10. ドキュメントと使用例の作成
  - uvインストールと使用方法を含む包括的READMEを作成
  - `uv run`コマンドでクローラーを実行する方法を文書化
  - すべてのクラスとメソッドのコードドキュメントとdocstringを追加
  - uvを使用した異なる使用ケースを示すサンプルスクリプトを作成
  - _要件: 6.1, 6.4, 6.5_