# 要件定義書

## 概要

WEBサイトのURLを入力として受け取り、そのサイト内のリンクを再帰的に探索して一覧を出力するスクリプトです。指定されたドメイン内のページを効率的にクロールし、発見されたすべてのリンクを構造化された形式で出力します。

## 要件

### 要件 1

**ユーザーストーリー:** ユーザーとして、WEBサイトのURLを入力して、そのサイト内のすべてのリンクを再帰的に取得したい。サイト構造を分析し、利用可能なすべてのページを発見するため。

#### 受け入れ基準

1. 有効なURLが提供された時、システムはそのURLからクロールを開始する
2. ページをクロールする時、システムはアンカータグからすべてのhrefリンクを抽出する
3. リンクが見つかった時、同じドメインに属する場合はクロールキューに追加する
4. すべてのページがクロールされた時、システムは発見されたURLの完全なリストを出力する

### 要件 2

**ユーザーストーリー:** ユーザーとして、クローラーが同一ドメインの境界を尊重してほしい。不要に外部サイトをクロールしないため。

#### 受け入れ基準

1. 発見されたリンクを分析する時、システムは開始URLと同じドメインに属するかチェックする
2. リンクが外部の時、システムは記録するがそれ以上クロールしない
3. リンクが内部の時、システムはクロールキューに追加する
4. ドメイン境界を決定する時、システムはサブドメインを適切に処理する

### 要件 3

**ユーザーストーリー:** ユーザーとして、無限ループと重複処理を避けたい。クローラーが効率的に完了するため。

#### 受け入れ基準

1. URLに遭遇した時、システムは既に処理済みかチェックする
2. URLが処理済みの時、システムは重複を避けるためスキップする
3. クロール深度が過度になった時、システムは設定可能な制限を持つ
4. 循環参照が存在する時、システムは適切に処理する

### 要件 4

**ユーザーストーリー:** ユーザーとして、出力が適切にフォーマットされ情報豊富であってほしい。サイト構造を簡単に理解するため。

#### 受け入れ基準

1. 結果を出力する時、システムは読みやすい形式でURLを表示する
2. 結果を表示する時、システムは各URLの深度レベルを示す
3. クロールが完了した時、システムは要約統計を表示する
4. エラーが発生した時、システムは全体プロセスを停止せずに明確に報告する

### 要件 5

**ユーザーストーリー:** ユーザーとして、クローラーが様々なエッジケースを適切に処理してほしい。異なるWEBサイトで確実に動作するため。

#### 受け入れ基準

1. HTTPエラーに遭遇した時、システムはエラーをログに記録し他のURLで継続する
2. 不正なHTMLを解析する時、システムは可能な限り抽出して継続する
3. ネットワークタイムアウトが発生した時、システムは指数バックオフで再試行する
4. レート制限が必要な時、システムはリクエスト間に遅延を実装する

### 要件 6

**ユーザーストーリー:** ユーザーとして、クローラーの動作を設定したい。異なる用途に適応させるため。

#### 受け入れ基準

1. クローラーを開始する時、システムは設定用のコマンドライン引数を受け入れる
2. 最大深度を設定する時、システムは指定されたクロール深度制限を尊重する
3. 遅延を設定する時、システムはリクエスト間に指定された時間待機する
4. 出力形式を設定する時、システムは異なる出力形式（テキスト、JSON、CSV）をサポートする